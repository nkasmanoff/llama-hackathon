{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "Add the llm verifier to check the thought process and see if this leads to a faster convergence\n",
    "\n",
    "Fix exact match reward, also report as a bug on unsloth github\n",
    "\n",
    "Create new dataset which uses the brain teasers I know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (2025.5.7)\n",
      "Requirement already satisfied: vllm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (0.8.5.post1)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (2025.5.8)\n",
      "Requirement already satisfied: torch>=2.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (2.6.0)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.0.29.post2)\n",
      "Requirement already satisfied: bitsandbytes in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.45.5)\n",
      "Requirement already satisfied: triton>=3.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (3.2.0)\n",
      "Requirement already satisfied: packaging in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (24.2)\n",
      "Requirement already satisfied: tyro in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.9.21)\n",
      "Requirement already satisfied: transformers!=4.47.0,==4.51.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (4.51.3)\n",
      "Requirement already satisfied: datasets>=3.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (7.0.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (1.7.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.15.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.32.0)\n",
      "Requirement already satisfied: hf_transfer in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.33.1)\n",
      "Requirement already satisfied: torchvision in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: filelock in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2024.11.6)\n",
      "Requirement already satisfied: requests in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub->unsloth) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub->unsloth) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from huggingface_hub->unsloth) (1.1.2)\n",
      "Requirement already satisfied: rich in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\n",
      "Requirement already satisfied: cachetools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (5.5.2)\n",
      "Requirement already satisfied: blake3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.0.5)\n",
      "Requirement already satisfied: py-cpuinfo in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (9.0.0)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.115.12)\n",
      "Requirement already satisfied: aiohttp in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (3.11.18)\n",
      "Requirement already satisfied: openai>=1.52.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.82.0)\n",
      "Requirement already satisfied: pydantic>=2.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (2.11.4)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.21.1)\n",
      "Requirement already satisfied: pillow in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (11.2.1)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.9.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.10.11)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.7.24)\n",
      "Requirement already satisfied: outlines==0.1.11 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.1.18)\n",
      "Requirement already satisfied: partial-json-parser in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.2.1.1.post5)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (26.4.0)\n",
      "Requirement already satisfied: msgspec in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.19.0)\n",
      "Requirement already satisfied: gguf>=0.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.16.3)\n",
      "Requirement already satisfied: importlib_metadata in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (8.0.0)\n",
      "Requirement already satisfied: mistral_common>=1.5.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from mistral_common[opencv]>=1.5.4->vllm) (1.5.6)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (4.11.0.86)\n",
      "Requirement already satisfied: einops in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.9.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.9.3)\n",
      "Requirement already satisfied: depyf==0.18.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.0.5)\n",
      "Requirement already satisfied: python-json-logger in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (3.3.0)\n",
      "Requirement already satisfied: scipy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.11.4)\n",
      "Requirement already satisfied: ninja in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.11.1.4)\n",
      "Requirement already satisfied: opentelemetry-sdk<1.27.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-api<1.27.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp<1.27.0,>=1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions-ai<0.5.0,>=0.4.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.4.9)\n",
      "Requirement already satisfied: numba==0.61.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (0.61.2)\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (2.46.0)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from vllm) (2.6.0)\n",
      "Requirement already satisfied: astor in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from depyf==0.18.0->vllm) (0.8.1)\n",
      "Requirement already satisfied: dill in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from depyf==0.18.0->vllm) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from numba==0.61.2->vllm) (0.44.0)\n",
      "Requirement already satisfied: interegular in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (5.6.3)\n",
      "Requirement already satisfied: referencing in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (4.23.0)\n",
      "Requirement already satisfied: pycountry in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (20250523)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from outlines==0.1.11->vllm) (0.1.26)\n",
      "Requirement already satisfied: networkx in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.2.18)\n",
      "Requirement already satisfied: zipp>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from importlib_metadata->vllm) (3.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.71.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.26.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc==1.26.0->opentelemetry-exporter-otlp<1.27.0,>=1.26.0->vllm) (1.26.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from opentelemetry-sdk<1.27.0,>=1.26.0->vllm) (0.47b0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2025.4.26)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth) (20.0.0)\n",
      "Requirement already satisfied: pandas in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth) (2.1.4)\n",
      "Requirement already satisfied: xxhash in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from aiohttp->vllm) (1.20.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<1.27.0,>=1.26.0->vllm) (1.17.2)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (0.46.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=2.9->vllm) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pydantic>=2.9->vllm) (0.4.0)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm) (1.3.1)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.0.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.28.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm) (2.2.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.34.2)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm) (2.7.0)\n",
      "Requirement already satisfied: typer>=0.12.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.15.4)\n",
      "Requirement already satisfied: rich-toolkit>=0.11.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.14.6)\n",
      "Requirement already satisfied: httpcore==1.* in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]>=0.115.0->vllm) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm) (0.24.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from openai>=1.52.0->vllm) (0.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (8.1.8)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: cupy-cuda12x in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm) (13.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.5.4)\n",
      "Requirement already satisfied: cut_cross_entropy in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from unsloth_zoo>=2025.5.8->unsloth) (25.1.1)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (1.1.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm) (15.0.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tyro->unsloth) (0.16)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from tyro->unsloth) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "#@title Colab Extra Install { display-mode: \"form\" }\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    !pip install --no-deps unsloth vllm\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    # Skip restarting message in Colab\n",
    "    import sys, re, requests; modules = list(sys.modules.keys())\n",
    "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "    \n",
    "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
    "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
    "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
    "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
    "    !pip install -r vllm_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 05-25 19:33:28 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-25 19:33:28 [__init__.py:239] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.5.7: Fast Gemma3 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.168 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "max_seq_length = 1024\n",
    "\n",
    "fourbit_models = [\n",
    "    # 4bit dynamic quants for superior accuracy and low memory use\n",
    "    \"unsloth/gemma-3-1b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-12b-it-unsloth-bnb-4bit\",\n",
    "    \"unsloth/gemma-3-27b-it-unsloth-bnb-4bit\",\n",
    "\n",
    "    # Other popular models!\n",
    "    \"unsloth/Llama-3.1-8B\",\n",
    "    \"unsloth/Llama-3.2-3B\",\n",
    "    \"unsloth/Llama-3.3-70B\",\n",
    "    \"unsloth/mistral-7b-instruct-v0.3\",\n",
    "    \"unsloth/Phi-4\",\n",
    "] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B\",\n",
    "    max_seq_length = max_seq_length, # Choose any for long context!\n",
    "    load_in_4bit = False,  # 4 bit quantization to reduce memory\n",
    "    load_in_8bit = False, # [NEW!] A bit more accurate, uses 2x memory\n",
    "    full_finetuning = True, # [NEW!] We have full finetuning now!\n",
    "    # token = \"hf_...\", # use one if using gated models\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # Turn off for just text!\n",
    "    finetune_language_layers   = True,  # Should leave on!\n",
    "    finetune_attention_modules = True,  # Attention good for GRPO\n",
    "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
    "\n",
    "    r = 8,           # Larger = higher accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "#dataset = load_dataset(\"openai/gsm8k\", \"main\", split = \"train\")\n",
    "#dataset\n",
    "\n",
    "# load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7a8a3f8dbe40ec9fe8a05d8a5cd557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load dataset from a json \n",
    "file_path = 'brain_teasers.json'\n",
    "dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files=file_path,\n",
    "    split='train'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given a problem.\n",
      "Think about the problem and provide your working out.\n",
      "Place it between <thinking> and </thinking>.\n",
      "Then, provide your solution between <answer></answer>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cac38b026143db96b80fa82df0f841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'How many rs in strawberry',\n",
       " 'answer': None,\n",
       " 'prompt': [{'content': 'You are given a problem.\\nThink about the problem and provide your working out.\\nPlace it between <thinking> and </thinking>.\\nThen, provide your solution between <answer></answer>',\n",
       "   'role': 'system'},\n",
       "  {'content': 'How many rs in strawberry', 'role': 'user'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasoning_start = \"<thinking>\"\n",
    "reasoning_end   = \"</thinking>\"\n",
    "solution_start = \"<response>\"\n",
    "solution_end = \"</response>\"\n",
    "\n",
    "system_prompt = \\\n",
    "f\"\"\"You are given a world class reasoning large language model.\n",
    "You are given a message below and return extremely valuable responses. To decide on that response, you must first *think* about what the user is asking you.\n",
    "\n",
    "Place your thinking between {reasoning_start} and {reasoning_end}.\n",
    "Then, provide your response between {solution_start}{solution_end}\"\"\"\n",
    "print(system_prompt)\n",
    "\n",
    "\n",
    "def extract_hash_answer(text):\n",
    "    if \"####\" not in text: return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "extract_hash_answer(dataset[0][\"answer\"])\n",
    "\n",
    "dataset = dataset.map(lambda x: {\n",
    "    \"prompt\" : [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\",   \"content\": x[\"question\"]},\n",
    "    ],\n",
    "    \"answer\": extract_hash_answer(x[\"answer\"]),\n",
    "})\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\\\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
    "    rf\"{solution_start}(.+?){solution_end}\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "\n",
    "\n",
    "thoughts_match_format = re.compile(\n",
    "    rf\"^[\\s]{{0,}}\"\\\n",
    "    rf\"{reasoning_start}.+?{reasoning_end}.*?\"\\\n",
    "    rf\"[\\s]{{0,}}$\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_exactly(completions, **kwargs):\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Match if format is seen exactly!\n",
    "        if match_format.search(response) is not None: score += 3.0\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_format_approximately(completions, **kwargs):\n",
    "    scores = []\n",
    "    for completion in completions:\n",
    "        score = 0\n",
    "        response = completion[0][\"content\"]\n",
    "        # Count how many keywords are seen - we penalize if too many!\n",
    "        # If we see 1, then plus some points!\n",
    "        score += 0.5 if response.count(reasoning_start) == 1 else -0.5\n",
    "        score += 0.5 if response.count(reasoning_end)   == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_start)  == 1 else -0.5\n",
    "        score += 0.5 if response.count(solution_end)    == 1 else -0.5\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer(prompts, completions, answer, **kwargs):\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_format.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        score = 0\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Correct answer gets 3 points!\n",
    "        if guess == true_answer:\n",
    "            score += 3.0\n",
    "        # Match if spaces are seen\n",
    "        elif guess.strip() == true_answer.strip():\n",
    "            score += 1.5\n",
    "        else:\n",
    "            # We also reward it if the answer is close via ratios!\n",
    "            # Ie if the answer is within some range, reward it!\n",
    "            try:\n",
    "                ratio = float(guess) / float(true_answer)\n",
    "                if   ratio >= 0.9 and ratio <= 1.1: score += 0.5\n",
    "                elif ratio >= 0.8 and ratio <= 1.2: score += 0.25\n",
    "                else: score -= 1.0 # Penalize wrong answers\n",
    "            except:\n",
    "                score -= 0.5 # Penalize\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['123.45']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_numbers = re.compile(\n",
    "    rf\"{solution_start}.*?([\\d\\.,]{{1,}})\",\n",
    "    flags = re.MULTILINE | re.DOTALL\n",
    ")\n",
    "match_numbers.findall(\"<answer>123.45</answer>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numbers(prompts, completions, answer, **kwargs):\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    extracted_responses = [\n",
    "        guess.group(1)\n",
    "        if (guess := match_numbers.search(r)) is not None else None \\\n",
    "        for r in responses\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    print('*'*20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
    "    for guess, true_answer in zip(extracted_responses, answer):\n",
    "        if guess is None:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "        # Convert to numbers\n",
    "        try:\n",
    "            true_answer = float(true_answer.strip())\n",
    "            guess       = float(guess.strip())\n",
    "            scores.append(1.5 if guess == true_answer else 0.0)\n",
    "        except:\n",
    "            scores.append(0)\n",
    "            continue\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.\n",
    "from typing import Optional\n",
    "def extract_xml(response: str, xml_tag: str) -> Optional[str]:\n",
    "    \"\"\"Extract content from XML tags in the response.\"\"\"\n",
    "    try:\n",
    "        xml_start = f\"<{xml_tag}>\"\n",
    "        xml_end = f\"</{xml_tag}>\"\n",
    "        return response.split(xml_start)[1].split(xml_end)[0].replace(\"\\n\", \" \").strip()\n",
    "    except (IndexError, AttributeError):\n",
    "        return None\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n",
    "\n",
    ")\n",
    "\n",
    "judge_model = \"cohere/command-a\"\n",
    "\n",
    "def evaluate_thought_process(prompt, completion):\n",
    "    evaluation_prompt = \"\"\"You are a logical reasoning assessment tool designed to evaluate the quality of thought processes in AI-generated responses. Your task is to analyze a given response to a question and assign a score from 0 to 10 based on the logical soundness of the reasoning that led to the conclusion.\n",
    "\n",
    "Scoring Criteria:\n",
    "0-2: No thought process provided\n",
    "3-4: Short thought process, and contains factual errors or is otherwise incorrect\n",
    "5-6: Generally reasonable but contains factual errors or is otherwise incorrect\n",
    "7-8: Sound logical structure with minor issues in reasoning or explanation\n",
    "9-10: Similar process to how a human would answer the question, and contains no factual errors\n",
    "\n",
    "Output Format:\n",
    "Please provide your response within XML tags. First reply with the reasoning used to reach the result found, followed by the score as an integer between 0 and 10.\n",
    "\n",
    "Example:\n",
    "<reasoning>The reasoning is flawed because the conclusion does not logically follow from the premises.</reasoning>\n",
    "<score>2</score>\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": evaluation_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Question: {prompt}\\nAnswer: {completion}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "                model=judge_model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "            )    \n",
    "\n",
    "    score = float(\n",
    "        extract_xml(response.choices[0].message.content, \"score\") or 0\n",
    "    )\n",
    "    reason = extract_xml(response.choices[0].message.content, \"reasoning\") or \"No reasoning provided\"\n",
    "    return score, reason\n",
    "\n",
    "\n",
    "def check_thought_process(prompts, completions, answer, **kwargs):\n",
    "    question = prompts[0][-1][\"content\"]\n",
    "    responses = [completion[0][\"content\"] for completion in completions]\n",
    "\n",
    "    scores = []\n",
    "    reasons = []\n",
    "    for prompt, completion in zip(prompts, responses):\n",
    "        # Extract the thought process and score from the completion\n",
    "        \n",
    "        # Evaluate the thought process\n",
    "        score, reason = evaluate_thought_process(prompt[-1][\"content\"], completion)\n",
    "        reasons.append(reason)\n",
    "        scores.append(score)\n",
    "\n",
    "    print(\"CHECKING THOUGHTS\")\n",
    "    print('*'*20, f\"Question:\\n{question}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nScore:\\n{scores[0]}\", f\"\\nReason:\\n{reasons[0]}\")\n",
    "    print(\"=\"*20)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
      "We will change the batch size of 1 to the `num_generations` of 4\n"
     ]
    }
   ],
   "source": [
    "max_prompt_length = 256\n",
    "\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "training_args = GRPOConfig(\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_torch_fused\",\n",
    "    logging_steps = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
    "    num_generations = 4, # Decrease if out of memory\n",
    "    max_prompt_length = max_prompt_length,\n",
    "    max_completion_length = max_seq_length - max_prompt_length,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 50,\n",
    "    save_steps = 50,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 6 | Num Epochs = 9 | Total steps = 50\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 1 x 1) = 4\n",
      " \"-____-\"     Trainable parameters = 6,522,880/1,006,408,832 (0.65% trained)\n",
      "`generation_config` default values have been modified to match model-specific defaults: {'max_length': 32768, 'top_k': 64, 'top_p': 0.95, 'bos_token_id': 2, 'eos_token_id': [1, 106]}. If this is not desired, please set these values explicitly.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "how many players have played for the nets and sixers \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a classic probability problem involving the number of players on each team. We need to determine how many players have played for both the Nets and the Sixers.  We'll use the principle of inclusion-exclusion.\n",
      "\n",
      "Let N be the set of players on the Nets, and let S be the set of players on the Sixers. We want to find |N ∪ S|.\n",
      "\n",
      "The total number of players on each team is not explicitly given. However, we can estimate the number of players on each team based on their current rosters. Let's assume the current rosters are complete and that the number of players on each team is reasonably high (e.g., 150-200 players).\n",
      "\n",
      "The number of players on the Nets is |N| = 150.\n",
      "The number of players on the Sixers is |S| = 150.\n",
      "\n",
      "We want to find |N ∪ S|. Using the principle of inclusion-exclusion:\n",
      "\n",
      "|N ∪ S| = |N| + |S| - |N ∩ S|\n",
      "\n",
      "We don't have information about the intersection of the two sets, |N ∩ S|. However, we can make an educated guess. The number of players who have played for *both* teams is likely to be relatively small.  Let's assume that the number of players who have played for both teams is a small constant, say 'x'.\n",
      "\n",
      "Then, |N ∪ S| = 150 + 150 - x = 300 - x\n",
      "\n",
      "We are asked to find the number of players who have played for *both* teams.  We are looking for |N ∩ S|. We can't determine this precisely without more information. However, we can estimate the maximum possible value for |N ∩ S|.  The maximum value for |N ∩ S|| would be the smaller of |N| and |S|. In this case, it's 150.  The minimum value would be 0, which would mean no one has played for both teams.\n",
      "\n",
      "Let's assume, for the sake of this exercise, that the number of players who have played for both teams is 50.  Then |N ∩ S| = 50.\n",
      "\n",
      "|N ∪ S| = 150 + 150 - 50 = 250\n",
      "\n",
      "Therefore, the number of players who have played for the Nets and sixers is approximately 250.\n",
      "\n",
      "<answer>250</answer] \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed because it makes several assumptions without supporting evidence. The answer assumes the number of players on each team (150) and the number of players who have played for both teams (50) without any data or sources to back these numbers. The use of the inclusion-exclusion principle is correct in theory, but the application is based on arbitrary values rather than actual data. Additionally, the question asks for the number of players who have played for both teams, but the answer calculates the total number of unique players across both teams, which is not the same thing. The correct approach would involve researching the actual rosters and player histories of both teams to determine the overlap.\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/50 11:54 < 21:42, 0.02 it/s, Epoch 3/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>reward</th>\n",
       "      <th>reward_std</th>\n",
       "      <th>completion_length</th>\n",
       "      <th>kl</th>\n",
       "      <th>rewards / check_thought_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.258306</td>\n",
       "      <td>230.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>433.750000</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>277.500000</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>2.081666</td>\n",
       "      <td>409.500000</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>5.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>70.750000</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>8.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>154.750000</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>358.750000</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>289.500000</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.559026</td>\n",
       "      <td>372.250000</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.707825</td>\n",
       "      <td>323.750000</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>6.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>189.750000</td>\n",
       "      <td>0.001833</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>463.500000</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many countries have a flag with exactly three colors \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The problem asks us to find the number of countries with flags that have exactly three colors. We need to think of all the countries and examine their flags.\n",
      "\n",
      "Let's consider some common examples:\n",
      "- China: Red, Yellow, Black\n",
      "- Netherlands: Red, White, Blue\n",
      "- Spain: Red, Yellow, Blue\n",
      "- Brazil: Green, Yellow, Red\n",
      "- Egypt: Red, White, Brown\n",
      "- Japan: Red, Blue, Black\n",
      "- South Korea: Red, Yellow, Green\n",
      "\n",
      "We are looking for countries with a flag that contains three distinct colors.\n",
      "\n",
      "- China: Red, Yellow, Black\n",
      "- Netherlands: Red, White, Blue\n",
      "- Spain: Red, Yellow, Blue\n",
      "- Brazil: Green, Yellow, Red\n",
      "- Egypt: Red, White, Brown\n",
      "- Japan: Red, Blue, Black\n",
      "- South Korea: Red, Yellow, Green\n",
      "\n",
      "We have identified the following countries with flags that have exactly three colors:\n",
      "- China\n",
      "- Netherlands\n",
      "- Spain\n",
      "- Brazil\n",
      "- Egypt\n",
      "- Japan\n",
      "- South Korea\n",
      "\n",
      "Counting the countries, we have 7 countries.\n",
      "\n",
      "</thinking>\n",
      "<answer>7</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed due to several inaccuracies in the color descriptions of the flags. Here are the correct color schemes for the mentioned countries:  - **China**: Red and Yellow (not three colors). - **Netherlands**: Red, White, and Blue (correct). - **Spain**: Red and Yellow (not three colors). - **Brazil**: Green, Yellow, and Blue (not Red). - **Egypt**: Red, White, and Black (not Brown). - **Japan**: Red and White (not three colors). - **South Korea**: Red, Blue, and Black (not Green).  Correcting these, the countries with exactly three colors are: - Netherlands: Red, White, Blue - Egypt: Red, White, Black - Brazil: Green, Yellow, Blue - South Korea: Red, Blue, Black  Thus, the correct count is 4 countries, not 7. The reasoning incorrectly included countries with fewer than three colors and misidentified some colors.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chemical elements have symbols that don't match their English names \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a classic logic puzzle! The trick is to think about the possible combinations of symbols. We need to consider elements that have symbols that are *completely* different from their English names. Let's start by listing the elements and their symbols:\n",
      "\n",
      "*   Hydrogen (H) -  H\n",
      "*   Helium (He) -  He\n",
      "*   Lithium (Li) -  Li\n",
      "*   Boron (B) -  B\n",
      "*   Carbon (C) -  C\n",
      "*   Nitrogen (N) -  N\n",
      "*   Oxygen (O) -  O\n",
      "*   Fluorine (F) -  F\n",
      "*   Sodium (Na) -  Na\n",
      "*   Magnesium (Mg) -  Mg\n",
      "*   Aluminum (Al) -  Al\n",
      "*   Silicon (Si) -  Si\n",
      "*   Phosphorus (P) -  P\n",
      "*   Sulfur (S) -  S\n",
      "*   Chlorine (Cl) -  Cl\n",
      "*   Potassium (K) -  K\n",
      "*   Iron (Fe) -  Fe\n",
      "*   Copper (Cu) -  Cu\n",
      "*   Zinc (Zn) -  Zn\n",
      "*   Iodine (I) -  I\n",
      "*   Silver (Ag) -  Ag\n",
      "*   Gold (Au) -  Au\n",
      "\n",
      "Now, let's identify the elements with symbols that don't match their English names:\n",
      "\n",
      "*   Fluorine (F)\n",
      "*   Chlorine (Cl)\n",
      "*   Iodine (I)\n",
      "*   Silver (Ag)\n",
      "*   Gold (Au)\n",
      "\n",
      "Therefore, there are 5 elements with symbols that don't match their English names.\n",
      "\n",
      "</thinking>\n",
      "\n",
      "<answer>5</answer> \n",
      "Score:\n",
      "6.0 \n",
      "Reason:\n",
      "The reasoning provided is generally sound, but it contains a significant oversight. The list of elements and their symbols is accurate, but the conclusion that only 5 elements have symbols that don't match their English names is incorrect. The thought process fails to account for several other elements whose symbols are derived from their Latin or Greek names, not their English names. For example, Sodium (Na) comes from \"Natrium,\" Potassium (K) from \"Kalium,\" Iron (Fe) from \"Ferrum,\" Copper (Cu) from \"Cuprum,\" and many others. These elements should also be included in the count. Therefore, the reasoning is flawed due to this omission.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many presidents were born in one of the 13 original colonies \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The question asks how many presidents were born in one of the 13 original colonies. This means we need to identify all the presidents who were born during the time period of the thirteen original colonies, which generally refers to the 17th century (roughly 1600-1776).\n",
      "\n",
      "Here's a breakdown of the key presidents and their birth years:\n",
      "\n",
      "*   **John Adams:** 1735\n",
      "*   **Benjamin Franklin:** 1707\n",
      "*   **George Washington:** 1732\n",
      "*   **John Hancock:** 1737\n",
      "*   **Samuel Adams:** 1745\n",
      "*   **Robert Morris:** 1734\n",
      "*   **Thomas Jefferson:** 1743\n",
      "*   **James Madison:** 1751\n",
      "*   **James Monroe:** 1758\n",
      "*   **John Quincy Adams:** 1767\n",
      "*   **George Washington:** 1732\n",
      "*   **Thomas Jefferson:** 1743\n",
      "*   **Martin Van Buren:** 1782\n",
      "*   **Andrew Jackson:** 1767\n",
      "\n",
      "Therefore, there were 12 presidents born in one of the 13 original colonies.\n",
      "\n",
      "</thinking>\n",
      "\n",
      "<answer>12</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed for several reasons. First, the list includes individuals who were not U.S. presidents, such as Benjamin Franklin, John Hancock, Samuel Adams, and Robert Morris. Second, it incorrectly lists George Washington and Thomas Jefferson twice. Third, the inclusion of Martin Van Buren (born in 1782) is incorrect because he was born after the Revolutionary War and the establishment of the United States, not during the colonial period. Fourth, the list omits several presidents who were indeed born in the original 13 colonies, such as John Adams, James Madison, James Monroe, and John Quincy Adams, though some of these names are listed, the overall count is incorrect due to the errors mentioned. The correct approach would be to identify all U.S. presidents born in the 13 original colonies and count them accurately.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chess pieces in the standard starting position are both on dark squares and can move on that player's first turn \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The question asks about the number of chess pieces in the standard starting position that are both on dark squares and can move on the first turn of a player. Let's analyze this carefully.\n",
      "The standard starting position involves:\n",
      "- 1 King\n",
      "- 1 Queen\n",
      "- 2 Rooks\n",
      "- 2 Bishops\n",
      "- 2 Knights\n",
      "- 8 Pawns\n",
      "\n",
      "We need to identify which pieces are on dark squares and can move on the first turn.\n",
      "- **King:** The King is always on a dark square. It can move to any dark square. Therefore, the King is a valid piece.\n",
      "- **Queen:** The Queen is on a light square. It cannot move on the first turn.\n",
      "- **Rooks:** The Rooks are on light squares. They cannot move on the first turn.\n",
      "- **Bishops:** The Bishops are on dark squares. They can move to any dark square.\n",
      "- **Knights:** The Knights are on light squares. They cannot move on the first turn.\n",
      "- **Pawns:** The Pawns are on dark squares. They can move one square forward, or two squares forward on their first turn.\n",
      "\n",
      "So, the pieces that are both on dark squares and can move on the first turn are:\n",
      "- King\n",
      "- Rooks\n",
      "- Bishops\n",
      "- Knights\n",
      "- Pawns\n",
      "\n",
      "There are 6 such pieces.\n",
      "\n",
      "</thinking>\n",
      "<answer>6</answer> \n",
      "Score:\n",
      "6.0 \n",
      "Reason:\n",
      "The reasoning provided is mostly correct but contains a factual error in the final count. The analysis correctly identifies the pieces on dark squares and their ability to move on the first turn. However, the conclusion incorrectly lists the Rooks and Knights as valid pieces, even though they are on light squares and cannot move on the first turn. The correct pieces that meet the criteria are the King, Bishops, and Pawns. Therefore, the correct count should be 1 King + 2 Bishops + 8 Pawns = 11 pieces.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many rs in strawberry \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The question asks how many Rs are in \"strawberry\".  \"Strawberry\" is a word consisting of the letters S, T, R, A, B, E, R, Y. There are 8 letters in total. The letter 'R' appears 3 times.  Therefore, the number of Rs in \"strawberry\" is 3.\n",
      "</thinking>\n",
      "\n",
      "<answer>3</answer> \n",
      "Score:\n",
      "10.0 \n",
      "Reason:\n",
      "The reasoning provided is clear and logically sound. The responder correctly identifies the letters in the word \"strawberry\" and counts the occurrences of the letter 'R'. The conclusion that there are 3 'R's in \"strawberry\" is accurate and directly follows from the analysis of the word's composition. The thought process is straightforward and mirrors how a human would approach this question.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many rs in strawberry \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a bit of a trick question! The number of \"rs\" in \"strawberry\" is simply the number of letters in the word \"strawberry\". \n",
      "\n",
      "<answer>\n",
      "zero</answer> \n",
      "Score:\n",
      "3.0 \n",
      "Reason:\n",
      "The reasoning provided is incorrect because it misinterprets the question. The question asks for the number of \"rs\" in \"strawberry,\" not the number of letters in the word. The correct approach is to count the occurrences of the letter \"r\" in the word \"strawberry.\" There are three \"r\"s in \"strawberry.\"\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many countries have a flag with exactly three colors \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "Let's analyze the flags of countries with exactly three colors. We need to find the number of countries that have a flag with three distinct colors.\n",
      "The flags of the following countries have exactly three colors:\n",
      "- Luxembourg\n",
      "- Panama\n",
      "- Maldives\n",
      "- Bhutan\n",
      "- Kenya\n",
      "-  and others with similar flag designs.\n",
      "\n",
      "However, the question asks for *countries* with a flag with exactly three colors.  It's possible that some flags with fewer colors might also fit this description.  Let's consider the most common flag designs.\n",
      "\n",
      "- Luxembourg: Red, White, Blue\n",
      "- Panama: Red, White, Blue\n",
      "- Maldives: Red, White, Blue\n",
      "- Bhutan: Red, Blue, Gold\n",
      "- Kenya: Red, White, Black\n",
      "-  and many others.\n",
      "\n",
      "Considering the most common flag designs, we can identify the following:\n",
      "- Luxembourg\n",
      "- Panama\n",
      "- Maldives\n",
      "- Bhutan\n",
      "- Kenya\n",
      "\n",
      "Therefore, there are 5 countries with a flag with exactly three colors.\n",
      "\n",
      "<answer>5</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The response attempts to list countries with flags that have exactly three colors, but it does not provide a comprehensive or accurate count. The reasoning is based on a limited and subjective selection of countries, and it does not consider the full range of national flags. Additionally, the conclusion that there are exactly 5 countries with such flags is not supported by a thorough analysis or reliable data. The thought process is incomplete and lacks a systematic approach to ensure accuracy.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chess pieces in the standard starting position are both on dark squares and can move on that player's first turn \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The problem asks about the number of chess pieces in the standard starting position that are both on dark squares and can move on the first turn of a player. This means we need to consider the pieces that are present in the starting position and can move on the first turn, specifically the pawns.  Pawns are the only pieces that can move.\n",
      "\n",
      "The starting position is standard, meaning it has a set of pieces.  We need to identify which pieces are on dark squares and can move on the first turn.\n",
      "\n",
      "The standard starting position has:\n",
      "- 8 pawns\n",
      "- 2 rooks\n",
      "- 2 knights\n",
      "- 2 bishops\n",
      "- 1 queen\n",
      "- 1 king\n",
      "\n",
      "Pawns are on dark squares, and they can move one square in any direction (horizontally, vertically, or diagonally).\n",
      "\n",
      "Therefore, all 8 pawns can move on the first turn.\n",
      "\n",
      "</thinking>\n",
      "<answer>8</answer> \n",
      "Score:\n",
      "7.0 \n",
      "Reason:\n",
      "The reasoning provided is generally sound but contains a minor factual error. The responder correctly identifies that pawns are the only pieces that can move on the first turn and that they are on dark squares in the standard starting position. However, the statement that pawns can move \"one square in any direction (horizontally, vertically, or diagonally)\" is incorrect. Pawns can only move forward, either one or two squares on their first move, and capture diagonally. Despite this error, the conclusion that all 8 pawns can move on the first turn is correct.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "how many players have played for the nets and sixers \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "To find out how many players have played for each team, I need to look at the official player rosters for the Nets and Sixers. I’ll need to consult reliable sports statistics websites like NBA.com or ESPN.com.  I’ll search for the current rosters for both teams.  I’ll then count the number of players listed for each team.\n",
      "\n",
      "<answer>\n",
      "The Nets have 36 players on their roster, and the Sixers have 35 players on their roster.</answer> \n",
      "Score:\n",
      "3.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed because it does not address the question accurately. The question asks for the number of players who have played for both the Nets and the Sixers, not the number of players currently on each team's roster. The correct approach would involve researching historical player data to identify individuals who have played for both franchises, which is a more complex task than simply checking current rosters. The provided answer is incorrect and does not align with the question's intent.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many presidents were born in one of the 13 original colonies \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The 13 original colonies were: Virginia, Massachusetts, Pennsylvania, New York, New Jersey, Connecticut, Rhode Island, Maryland, North Carolina, South Carolina, Delaware, and Virginia.  We need to determine how many of these presidents were born in those colonies.  This is a bit of a tricky question as it requires knowledge of the specific birthplaces of each president.  I'll need to consult a reliable source like the U.S. Presidents' Historical Database or a dedicated historical resource. \n",
      "\n",
      "Let's start with Virginia, which was the largest of the original colonies.  We need to find the number of presidents born in Virginia.  According to the U.S. Presidents’ Historical Database, the following presidents were born in Virginia: George Washington, John Adams, Thomas Jefferson, James Madison, James Monroe, Martin Van Buren, and Andrew Jackson.\n",
      "\n",
      "So, there were 7 presidents born in Virginia.\n",
      "\n",
      "Now, let's move on to Massachusetts, which was the second-largest.  The presidents born in Massachusetts include John Adams, John Hancock, and Samuel Adams.  That's 3 presidents.\n",
      "\n",
      "Next, we have Pennsylvania, which had a significant number of presidents.  The presidents born in Pennsylvania include Benjamin Franklin, George Washington, and many others.  It’s difficult to give an exact number, but we can estimate it to be around 10-12 presidents.\n",
      "\n",
      "New York, New Jersey, Connecticut, Rhode Island, and Maryland each had a relatively small number of presidents born in their respective states.  Let's estimate around 2-3 presidents per colony.\n",
      "\n",
      "North Carolina, South Carolina, and Delaware each had a small number of presidents born in their respective states.  Let's estimate around 1-2 presidents per colony.\n",
      "\n",
      "Total = 7 + 3 + 10 + 2 + 3 + 1 + 2 = 26\n",
      "\n",
      "Therefore, there were 26 presidents born in one of the 13 original colonies.\n",
      "\n",
      "</thinking>\n",
      "<answer>26</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed due to several inaccuracies and logical inconsistencies.   1. **Duplicate Colonies**: The list of original colonies includes \"Virginia\" twice, which is incorrect. The correct list of 13 original colonies is: Delaware, Pennsylvania, New Jersey, Georgia, Connecticut, Massachusetts, Maryland, South Carolina, New Hampshire, Virginia, New York, North Carolina, and Rhode Island.  2. **Incorrect Birthplace Assignments**:     - **John Adams** was born in Massachusetts, not Virginia.    - **Martin Van Buren** was born in New York, not Virginia.    - **Andrew Jackson** was born in South Carolina, not Virginia.    - **Benjamin Franklin** was not a president; he was a Founding Father and diplomat.  3. **Overestimation**: The estimate of 10-12 presidents born in Pennsylvania is grossly overstated. Only one president, James Buchanan, was born in Pennsylvania.  4. **Underestimation**: The estimate of 1-2 presidents for North Carolina, South Carolina, and Delaware is partially correct but lacks specificity. James K. Polk (North Carolina), Andrew Jackson (South Carolina), and Joe Biden (Delaware) are notable examples.  5. **Incorrect Total Calculation**: The final total of 26 is incorrect due to the cumulative effect of these errors.  A correct approach would involve systematically listing each president and their birthplace, ensuring accuracy and avoiding duplication or misassignment.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chemical elements have symbols that don't match their English names \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>Okay, this is a classic logic puzzle! The key here is to think about what constitutes a “matching” symbol. A symbol doesn’t need to be a direct translation of the element’s name. It needs to be a recognizable representation of the element, even if it’s a slightly altered or abbreviated version.\n",
      "\n",
      "Let's consider the possibilities:\n",
      "\n",
      "*   **Hydrogen (H):**  Hydrogen doesn't have a traditional English name.  It’s a hydrogen atom.\n",
      "*   **Oxygen (O):** Oxygen doesn't have a traditional English name. It’s a basic oxide.\n",
      "*   **Nitrogen (N):** Nitrogen doesn't have a traditional English name. It’s a basic nitrogen compound.\n",
      "*   **Sodium (Na):** Sodium doesn’t have a traditional English name. It’s a basic sodium compound.\n",
      "*   **Magnesium (Mg):** Magnesium doesn’t have a traditional English name. It’s a basic magnesium compound.\n",
      "*   **Silicon (Si):** Silicon doesn’t have a traditional English name. It’s a basic silicon compound.\n",
      "*   **Phosphorus (P):** Phosphorus doesn’t have a traditional English name. It’s a basic phosphorus compound.\n",
      "\n",
      "Therefore, there are **7** chemical elements with symbols that don’t match their English names.\n",
      "\n",
      "</thinking>\n",
      "\n",
      "<answer>7</answer> \n",
      "Score:\n",
      "3.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed because it incorrectly assumes that elements like Hydrogen, Oxygen, Nitrogen, Sodium, Magnesium, Silicon, and Phosphorus have symbols that don't match their English names. In reality, the symbols for these elements (H, O, N, Na, Mg, Si, P) are derived from their Latin or Greek names, not from their English names. For example, Sodium (Na) comes from its Latin name \"Natrium.\" The correct approach would involve identifying elements whose symbols are not directly related to their English names, such as Tungsten (W, from its Latin name \"Wolfram\") or Gold (Au, from its Latin name \"Aurum\"). The provided reasoning fails to consider the historical and linguistic origins of element symbols, leading to an incorrect conclusion.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chemical elements have symbols that don't match their English names \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a classic logic puzzle! The key is to consider the constraints. We’re looking for elements with symbols that *don’t* correspond to their English names. This means we need to think about elements that are commonly represented by symbols that don't have a direct, straightforward English equivalent.\n",
      "\n",
      "Let's start by listing some common elements and their symbols:\n",
      "\n",
      "*   Hydrogen (H):  A simple, easily recognizable symbol.\n",
      "*   Oxygen (O):  A commonly used symbol.\n",
      "*   Carbon (C):  A fundamental element, often represented with a simple 'C'.\n",
      "*   Nitrogen (N):  Often symbolized with a 'N'.\n",
      "*   Sodium (Na):  A readily recognizable symbol.\n",
      "*   Magnesium (Mg):  A simple symbol.\n",
      "*   Aluminum (Al): A commonly used symbol.\n",
      "*   Silicon (Si):  A symbol that's relatively simple.\n",
      "*   Phosphorus (P): A symbol that is very simple.\n",
      "\n",
      "Now, let’s look at some elements with symbols that *don't* have a direct English equivalent:\n",
      "\n",
      "*   Boron (B):  While boron is important, it doesn't have a very common or easily understood English name.\n",
      "*   Sulfur (S):  Sulfur is a key element in many compounds, but its symbol isn’t particularly familiar.\n",
      "*   Chlorine (Cl):  Chlorine’s symbol is straightforward, but it’s a relatively niche element.\n",
      "*   Iodine (I):  Iodine has a symbol, but it's not a common everyday name.\n",
      "*   Fluorine (F):  Fluorine is a very specialized element.\n",
      "\n",
      "Therefore, there are **6** chemical elements with symbols that don't match their English names.\n",
      "\n",
      "</thinking>\n",
      "\n",
      "<answer>6</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed because it incorrectly identifies elements whose symbols don't match their English names. The thought process focuses on elements with symbols that are not \"common\" or \"easily understood,\" which is not the correct criterion. The actual criterion should be whether the symbol is derived from the element's English name or not. For example, Sodium (Na) comes from its Latin name \"Natrium,\" and Tungsten (W) comes from its German name \"Wolfram.\" The correct approach would involve identifying elements whose symbols are derived from names in languages other than English, such as Latin or Greek. The provided list does not accurately reflect this, leading to an incorrect conclusion.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many presidents were born in one of the 13 original colonies \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a classic riddle! The question is a bit of a trick. It asks for the number of presidents born in *one* of the 13 original colonies, not the total number of presidents born in all of them. \n",
      "\n",
      "The 13 original colonies were:\n",
      "*   Massachusetts\n",
      "*   Virginia\n",
      "*   New York\n",
      "*   New Jersey\n",
      "*   Pennsylvania\n",
      "*   Delaware\n",
      "*   Maryland\n",
      "*   North Carolina\n",
      "*   South Carolina\n",
      "*   Georgia\n",
      "*   Connecticut\n",
      "*   Rhode Island\n",
      "\n",
      "There were no presidents born in any of those colonies. Therefore, the answer is 0.\n",
      "\n",
      "</thinking>\n",
      "<answer>0</answer> \n",
      "Score:\n",
      "10.0 \n",
      "Reason:\n",
      "The reasoning provided is logically sound and correctly identifies the trick in the question. It accurately lists the 13 original colonies and concludes that no U.S. presidents were born in any of them, leading to the correct answer of 0. The thought process is clear, step-by-step, and mirrors how a human would approach the question, ensuring no factual errors.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many countries have a flag with exactly three colors \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "This is a classic pattern recognition problem. We need to identify countries whose flags have a distinct pattern of three colors.  Let's consider a few possibilities:\n",
      "*   **Algeria:**  The flag has a distinctive red, white, and black pattern.\n",
      "*   **Luxembourg:**  The flag has a unique pattern of red, white, and blue.\n",
      "*   **Azerbaijan:** The flag has a unique pattern of red, white, and blue.\n",
      "*   **Tunisia:** The flag has a unique pattern of red, green, and white.\n",
      "*   **Mauritania:** The flag has a unique pattern of red, yellow, and black.\n",
      "*   **Indonesia:** The flag has a distinctive pattern of red, blue, and yellow.\n",
      "*   **United Arab Emirates:** The flag has a distinctive pattern of red, white, and blue.\n",
      "\n",
      "It’s likely that other flags exist, but these are some of the most prominent examples. The key is the distinct pattern of three colors.  We need to systematically list countries that fit this description.\n",
      "\n",
      "<answer>\n",
      "Algeria, Luxembourg, Azerbaijan, Tunisia, Mauritania, Indonesia, United Arab Emirates</answer> \n",
      "Score:\n",
      "7.0 \n",
      "Reason:\n",
      "The response provides a reasonable approach to identifying countries with flags that have exactly three colors. It correctly identifies several countries (Algeria, Luxembourg, Azerbaijan, Tunisia, Mauritania, Indonesia, United Arab Emirates) whose flags indeed feature three distinct colors. However, the reasoning could be improved by acknowledging that the list is not exhaustive and that there are many more countries with three-color flags. Additionally, the response does not provide a systematic method for verifying the completeness of the list, such as referencing a comprehensive source like a flag database or encyclopedia. The thought process is generally sound but lacks thoroughness and verification.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "how many players have played for the nets and sixers \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "To determine the number of players who have played for each team, we need to consider all players who have played in games for either the Nets or the Sixers. This includes players who have played in both regular season and playoff games.\n",
      "We can calculate this by considering the total number of games played by each team and then subtracting the number of players who have played for only one team.\n",
      "\n",
      "Nets:\n",
      "- Regular season games: 77 (2023-2024)\n",
      "- Playoff games: 10 (2023-2024)\n",
      "Total regular season games: 77 + 10 = 87\n",
      "Total playoff games: 10\n",
      "Total games played: 87 + 10 = 97\n",
      "\n",
      "Sixers:\n",
      "- Regular season games: 76 (2023-2024)\n",
      "- Playoff games: 12 (2023-2024)\n",
      "Total regular season games: 76 + 12 = 88\n",
      "Total playoff games: 12\n",
      "Total games played: 88 + 12 = 100\n",
      "\n",
      "Players who have played for one team:\n",
      "- Nets: 87 players\n",
      "- Sixers: 100 players\n",
      "\n",
      "Players who have played for both teams:\n",
      "- Total games played: 97\n",
      "- Players who have played for one team: 87\n",
      "- Players who have played for both teams: 97 - 87 = 10\n",
      "\n",
      "Therefore, the number of players who have played for the Nets and sixers is 87 + 10 = 97.\n",
      "\n",
      "</thinking>\n",
      "<answer>97</answer] \n",
      "Score:\n",
      "3.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed and does not accurately determine the number of players who have played for both the Nets and the Sixers. The calculation incorrectly uses the total number of games played by each team and subtracts the number of players who have played for only one team, which is not a valid method for determining the number of players who have played for both teams. The correct approach would involve analyzing historical rosters of both teams and identifying players who appear on both lists. The provided calculation is based on incorrect assumptions and does not reflect the actual process of determining shared players between two teams.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many chess pieces in the standard starting position are both on dark squares and can move on that player's first turn \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The problem asks about the number of chess pieces in the standard starting position that are both on dark squares and can move on a player’s first turn. This is a relatively complex question that requires careful consideration of the chess rules. Let’s break it down:\n",
      "\n",
      "1. **Standard Starting Position:** We're dealing with the standard 8x8 chess board, with pieces placed as follows:\n",
      "   - Pawns: 8 on the first two rows.\n",
      "   - Rooks: 2 on the corners.\n",
      "   - Knights: 2 on the sides.\n",
      "   - Bishops: 2 on the corners.\n",
      "   - Queen: 1 on the center.\n",
      "   - King: 1 on the central square.\n",
      "\n",
      "2. **Dark Squares:** Dark squares are those that are not part of the white or black squares.  In the standard starting position, the dark squares are:\n",
      "   - Squares (a2, b2, c2, d2, e2, f2, g2, h2).  These are all the squares in the middle of the board.\n",
      "\n",
      "3. **Pieces on Dark Squares:** The pieces that are on dark squares are the pawns. There are 8 pawns on the dark squares.\n",
      "\n",
      "4. **First Turn Mobility:** A piece can move if it's on the chessboard.  The pawns are blocked by the other pieces on the board. Therefore, there are zero pieces that can move on a player’s first turn.\n",
      "\n",
      "<answer>0</answer> \n",
      "Score:\n",
      "4.0 \n",
      "Reason:\n",
      "The reasoning provided is flawed. The initial breakdown of the standard starting position is correct, but the analysis of dark squares and the mobility of pieces on the first turn is incorrect. Dark squares in chess are the black squares, not the middle squares as stated. Additionally, the pawns on the second rank (for White) and seventh rank (for Black) are indeed on dark squares and can move on the first turn. The knights, which are also on dark squares, can move on the first turn. Therefore, the correct pieces that meet the criteria are the pawns and knights on dark squares, not zero as concluded.\n",
      "====================\n",
      "CHECKING THOUGHTS\n",
      "******************** Question:\n",
      "How many rs in strawberry \n",
      "Answer:\n",
      "None \n",
      "Response:\n",
      "<thinking>\n",
      "The question asks for the number of Rs in \"strawberry\". This is a word puzzle! \"Rs\" is a common abbreviation for Indian Rupees.\n",
      "<answer>\n",
      "10</answer>\n",
      " \n",
      "Score:\n",
      "3.0 \n",
      "Reason:\n",
      "The response incorrectly interprets the question as a currency-related query, assuming \"Rs\" refers to Indian Rupees, which is not relevant to the word \"strawberry.\" The correct interpretation should focus on counting the occurrences of the letter \"r\" in the word \"strawberry.\" The word \"strawberry\" contains three \"r\"s. The provided answer of \"10\" is entirely unrelated to the actual task and demonstrates a misunderstanding of the question.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        check_thought_process\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_question = \"How many presidents were born in one of the thirteen original colonies?\"# \"How many pieces in chess start on a black tile and can move on the first turn?\"\n",
    "inference_prompt = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": inference_question}]\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    inference_prompt,\n",
    "    add_generation_prompt = True,\n",
    "    tokenize = False,\n",
    ")\n",
    "\n",
    "input_ids = tokenizer.encode(prompt, return_tensors = \"pt\")\n",
    "input_ids = input_ids.to(model.device)\n",
    "output = model.generate(input_ids, max_new_tokens=256,  do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=False, pad_token_id = tokenizer.eos_token_id)\n",
    "\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_question = \"How many pieces in chess start on a black tile and can move on the first turn?\"\n",
    "inference_prompt = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": inference_question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using this prompt and result, evaluate thought process\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
